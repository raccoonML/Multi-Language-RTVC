*****
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/sveneschlbeck/Multi-Language-RTVC)
![GitHub top language](https://img.shields.io/github/languages/top/sveneschlbeck/Multi-Language-RTVC)
![GitHub](https://img.shields.io/github/issues/sveneschlbeck/Multi-Language-RTVC)
![GitHub](https://img.shields.io/github/issues-pr/sveneschlbeck/Multi-Language-RTVC?color=orange)
![GitHub](https://img.shields.io/github/stars/sveneschlbeck/Multi-Language-RTVC?style=social)
![GitHub](https://img.shields.io/badge/License-MIT-brown.svg)
*****

![MLRTVC logo](img/MLRTVC_readme.png)

``Multi-Language-RTVC`` stands for Multi-Language Real Time Voice Cloning and is a Voice Cloning Tool capable
of transfering speaker-specific audio features to synthesize speeches in that voice based on just a few
seconds of unknown audio data.

## License

This code is licensed under ``MIT``. For more information regarding the license model or
associated duties and rights, click [here](LICENSE).

## Project History

This project was started in 2021 with the goal of inheriting Corentin Jemine's [``Real-Time-Voice-Cloning``](https://github.com/CorentinJ/Real-Time-Voice-Cloning).
The project originated from the wish of multi-language support for voice cloning models and is now
maintained and enhanced by contributing volunteers.

## Contributing

We welcome all those interested in the project, from beginners to experts. The MLRTVC community standard is
a nice, open-minded and efficient working climate. We encourage all those with ideas to take part in the
project by sharing their thoughts.  
There are multiple meaningful ways of contributing:

- Developing code (new features, fixes, enhancements)
- Writing documentation
- Raising issues (bugs, feature requests, enhancement proposals, code refacturing, etc.)
- Providing pre-trained models
- Participating in community tasks (code reviews, discussions, maintenance, etc.)

For transparacy reasons, we ask you to engage with this project via the official ways (issues, pull requests)
to share knowledge and questions publicly. Only in cases where privacy or confidentiality is of great importance,
other communication channels are accepted (email, chat, etc.).

Further information can be gained in the [``Contributing Guidelines``](CONTRIBUTING.md).

## Code of Conduct

Working together on this project, we share and defend certain values which are indispensable
for an Open Source project like ``MLRTVC``. For further information see [here](https://github.com/sveneschlbeck/Multi-Language-RTVC/blob/main/CODE_OF_CONDUCT.md).

## Theoretical Foundations

The applications in this repository are based on work done by different Computer Science and
Audio Engineering researches from the fields of Speaker Recognition, Audio Feature Extraction
and Data Processing. The following research papers contain deeper information on the theory
behind ``MLRTVC``:

| ``arxiv`` URL | Designation | Paper Title | Code Implementation |
| --- | ----------- | ----- | --------------------- |
|[Download](https://arxiv.org/pdf/1806.04558.pdf) | SV2TTS | Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis | [``RTVC``](https://github.com/CorentinJ/Real-Time-Voice-Cloning) |
|[Download](https://arxiv.org/pdf/1710.10467.pdf) | GE2E | Generalized End-To-End Loss for Speaker Verification | [``RTVC``](https://github.com/CorentinJ/Real-Time-Voice-Cloning) |
|[Download](https://arxiv.org/pdf/1802.08435.pdf) | WaveRNN | Efficient Neural Audio Synthesis | [``WaveRNN``](https://github.com/fatchord/WaveRNN) |
|[Download](https://arxiv.org/pdf/1703.10135.pdf) | Tacotron | Tacotron: Towards End-to-End Speech Synthesis | [``WaveRNN``](https://github.com/fatchord/WaveRNN)

## Help & Support

### Documentation

- FAQ: https://github.com/sveneschlbeck/Multi-Language-RTVC/wiki/Frequently-Asked-Questions-(FAQ)

### Communication

- Stack Overflow: https://stackoverflow.com/questions/tagged/mlrtvc
- GitHub Discussions: https://github.com/sveneschlbeck/Multi-Language-RTVC/discussions
